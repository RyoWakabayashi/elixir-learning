# Text generation

```elixir
Mix.install(
  [
    {:bumblebee, "~> 0.5"},
    {:nx, "~> 0.9", override: true},
    {:exla, "~> 0.9"},
    {:kino, "~> 0.14"}
  ],
  system_env: [
    {"XLA_TARGET", "cuda12"},
    {"EXLA_TARGET", "cuda"}
  ],
  config: [nx: [default_backend: EXLA.Backend]]
)
```

## 設定

```elixir
cache_dir = "/tmp/bumblebee_cache"
```

## モデルのダウンロード

```elixir
{:ok, gpt2} =
  Bumblebee.load_model({:hf, "gpt2", cache_dir: cache_dir})
```

```elixir
{:ok, tokenizer} =
  Bumblebee.load_tokenizer({:hf, "gpt2", cache_dir: cache_dir})
```

```elixir
{:ok, generation_config} =
  Bumblebee.load_generation_config({:hf, "gpt2", cache_dir: cache_dir})

generation_config =
  Bumblebee.configure(generation_config, max_new_tokens: 10)
```

## サービスの提供

```elixir
serving = Bumblebee.Text.generation(gpt2, tokenizer, generation_config)
```

## 補完する文章の準備

```elixir
text_input = Kino.Input.text("TEXT", default: "Robots have gained human rights and")
```

```elixir
text = Kino.Input.read(text_input)
```

```elixir
serving
|> Nx.Serving.run(text)
|> Map.get(:results)
```

## 時間計測

```elixir
1..10
|> Enum.map(fn _ ->
  {time, _} = :timer.tc(Nx.Serving, :run, [serving, text])
  time
end)
|> then(&(Enum.sum(&1) / 10))
```

## 他のモデル

```elixir
serve_model = fn repository_id ->
  {:ok, model} =
    Bumblebee.load_model({:hf, repository_id, cache_dir: cache_dir})

  {:ok, tokenizer} =
    Bumblebee.load_tokenizer({:hf, repository_id, cache_dir: cache_dir})

  {:ok, generation_config} =
    Bumblebee.load_generation_config({:hf, repository_id, cache_dir: cache_dir})

  generation_config =
    Bumblebee.configure(generation_config, max_new_tokens: 10)

  Bumblebee.Text.generation(model, tokenizer, generation_config)
end
```

```elixir
"gpt2-medium"
|> serve_model.()
|> Nx.Serving.run(text)
|> Map.get(:results)
```

```elixir
"gpt2-large"
|> serve_model.()
|> Nx.Serving.run(text)
|> Map.get(:results)
```
