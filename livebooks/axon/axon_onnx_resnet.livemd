# AxonOnnx ResNet

```elixir
Mix.install(
  [
    {:exla, "~> 0.4"},
    {:axon_onnx, "~> 0.3"},
    {:stb_image, "~> 0.6"},
    {:httpoison, "~> 1.8"},
    {:jason, "~> 1.4"},
    {:kino, "~> 0.8"}
  ],
  config: [nx: [default_backend: EXLA.Backend]]
)
```

## Download models

```elixir
classes =
  "https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
  |> HTTPoison.get!()
  |> then(&Jason.decode!(&1.body))
```

```elixir
model_path = "/data/resnet.onnx"

unless File.exists?(model_path) do
  "https://media.githubusercontent.com/media/onnx/models/main/vision/classification/resnet/model/resnet18-v1-7.onnx"
  |> HTTPoison.get!(receive_timeout: 300_000)
  |> then(&File.write!(model_path, &1.body))
end

{model, params} = AxonOnnx.import(model_path)
```

```elixir
img_path = "/data/shark.jpg"

img_tensor =
  "https://www.collinsdictionary.com/images/full/greatwhiteshark_157273892.jpg"
  |> HTTPoison.get!()
  |> then(&StbImage.read_binary!(&1.body))
  |> StbImage.to_nx()

Kino.Image.new(img_tensor)
```

```elixir
nx_channels = Nx.axis_size(img_tensor, 2)
```

```elixir
img_tensor =
  case nx_channels do
    3 -> img_tensor
    4 -> Nx.slice(img_tensor, [0, 0, 0], [224, 224, 3])
  end
  |> Nx.divide(255)
  |> Nx.subtract(Nx.tensor([0.485, 0.456, 0.406]))
  |> Nx.divide(Nx.tensor([0.229, 0.224, 0.225]))
  |> Nx.transpose()
  |> Nx.new_axis(0)
  |> dbg()
```

```elixir
model
|> Axon.predict(params, img_tensor)
|> Nx.flatten()
|> Nx.argsort()
|> Nx.reverse()
|> Nx.slice([0], [5])
|> Nx.to_flat_list()
|> Enum.with_index()
|> Enum.map(fn {no, index} -> {index, Map.get(classes, to_string(no))} end)
|> dbg()
```
